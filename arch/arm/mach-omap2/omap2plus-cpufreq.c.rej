diff a/arch/arm/mach-omap2/omap2plus-cpufreq.c b/arch/arm/mach-omap2/omap2plus-cpufreq.c	(rejected hunks)
@@ -42,6 +41,7 @@
 #include <mach/hardware.h>
 
 #include "dvfs.h"
+#include "smartreflex.h"
 
 #ifdef CONFIG_SMP
 struct lpj_info {
@@ -78,9 +80,40 @@ static unsigned int omap_getspeed(unsigned int cpu)
 	return rate;
 }
 
-static int omap_cpufreq_scale(unsigned int target_freq, unsigned int cur_freq)
+static void omap_cpufreq_lpj_recalculate(unsigned int target_freq,
+					 unsigned int cur_freq)
 {
+ #ifdef CONFIG_SMP
 	unsigned int i;
+
+	/*
+	 * Note that loops_per_jiffy is not updated on SMP systems in
+	 * cpufreq driver. So, update the per-CPU loops_per_jiffy value
+	 * on frequency transition. We need to update all dependent CPUs.
+	 */
+	for_each_possible_cpu(i) {
+		struct lpj_info *lpj = &per_cpu(lpj_ref, i);
+		if (!lpj->freq) {
+			lpj->ref = per_cpu(cpu_data, i).loops_per_jiffy;
+			lpj->freq = cur_freq;
+		}
+
+		per_cpu(cpu_data, i).loops_per_jiffy =
+			cpufreq_scale(lpj->ref, lpj->freq, target_freq);
+	}
+
+	/* And don't forget to adjust the global one */
+	if (!global_lpj_ref.freq) {
+		global_lpj_ref.ref = loops_per_jiffy;
+		global_lpj_ref.freq = cur_freq;
+	}
+	loops_per_jiffy = cpufreq_scale(global_lpj_ref.ref, global_lpj_ref.freq,
+					target_freq);
+#endif
+}
+
+static int omap_cpufreq_scale(unsigned int target_freq, unsigned int cur_freq)
+{
 	int ret;
 	struct cpufreq_freqs freqs;
 
@@ -107,35 +143,15 @@ static int omap_cpufreq_scale(unsigned int target_freq, unsigned int cur_freq)
 	pr_info("cpufreq-omap: transition: %u --> %u\n", freqs.old, freqs.new);
 #endif
 
+	if (target_freq > cur_freq)
+		omap_cpufreq_lpj_recalculate(freqs.new, freqs.old);
+
 	ret = omap_device_scale(mpu_dev, mpu_dev, freqs.new * 1000);
 
 	freqs.new = omap_getspeed(0);
 
-#ifdef CONFIG_SMP
-	/*
-	 * Note that loops_per_jiffy is not updated on SMP systems in
-	 * cpufreq driver. So, update the per-CPU loops_per_jiffy value
-	 * on frequency transition. We need to update all dependent CPUs.
-	 */
-	for_each_possible_cpu(i) {
-		struct lpj_info *lpj = &per_cpu(lpj_ref, i);
-		if (!lpj->freq) {
-			lpj->ref = per_cpu(cpu_data, i).loops_per_jiffy;
-			lpj->freq = freqs.old;
-		}
-
-		per_cpu(cpu_data, i).loops_per_jiffy =
-			cpufreq_scale(lpj->ref, lpj->freq, freqs.new);
-	}
-
-	/* And don't forget to adjust the global one */
-	if (!global_lpj_ref.freq) {
-		global_lpj_ref.ref = loops_per_jiffy;
-		global_lpj_ref.freq = freqs.old;
-	}
-	loops_per_jiffy = cpufreq_scale(global_lpj_ref.ref, global_lpj_ref.freq,
-					freqs.new);
-#endif
+	if (target_freq < cur_freq)
+		omap_cpufreq_lpj_recalculate(freqs.new, freqs.old);
 
 	/* notifiers */
 	for_each_online_cpu(freqs.cpu)
@@ -259,141 +275,51 @@ static int omap_target(struct cpufreq_policy *policy,
 	return ret;
 }
 
-static inline void freq_table_free(void)
-{
-	if (atomic_dec_and_test(&freq_table_users))
-		opp_free_cpufreq_table(mpu_dev, &freq_table);
-}
-
-#if defined(CONFIG_THERMAL_FRAMEWORK) || defined(CONFIG_OMAP4_DUTY_CYCLE)
-void omap_thermal_step_freq_down(void)
+static void omap_cpu_early_suspend(struct early_suspend *h)
 {
 	unsigned int cur;
 
-	if (!omap_cpufreq_ready) {
-		pr_warn_once("%s: Thermal throttle prior to CPUFREQ ready\n",
-			     __func__);
-		return;
-	}
-
 	mutex_lock(&omap_cpufreq_lock);
 
-	max_thermal = omap_thermal_lower_speed();
+	if (screen_off_max_freq) {
+		max_capped = screen_off_max_freq;
 
-	pr_warn("%s: temperature too high, starting cpu throttling at max %u\n",
-		__func__, max_thermal);
-
-	if (!omap_cpufreq_suspended) {
 		cur = omap_getspeed(0);
-		if (cur > max_thermal)
-			omap_cpufreq_scale(max_thermal, cur);
+		if (cur > max_capped)
+			omap_cpufreq_scale(max_capped, cur);
 	}
 
 	mutex_unlock(&omap_cpufreq_lock);
 }
 
-void omap_thermal_step_freq_up(void)
+static void omap_cpu_late_resume(struct early_suspend *h)
 {
 	unsigned int cur;
 
-	if (!omap_cpufreq_ready)
-		return;
-
 	mutex_lock(&omap_cpufreq_lock);
 
-	if (max_thermal == max_freq) {
-		pr_warn("%s: not throttling\n", __func__);
-		goto out;
-	}
+	if (max_capped) {
+		max_capped = 0;
 
-	max_thermal = max_freq;
-
-	pr_warn("%s: temperature reduced, stepping up to %i\n",
-		__func__, current_target_freq);
-
-	if (!omap_cpufreq_suspended) {
 		cur = omap_getspeed(0);
-		omap_cpufreq_scale(current_target_freq, cur);
+		if (cur != current_target_freq)
+			omap_cpufreq_scale(current_target_freq, cur);
 	}
-out:
-	mutex_unlock(&omap_cpufreq_lock);
-}
 
-/*
- * cpufreq_apply_cooling: based on requested cooling level, throttle the cpu
- * @param cooling_level: percentage of required cooling at the moment
- *
- * The maximum cpu frequency will be readjusted based on the required
- * cooling_level.
-*/
-static int cpufreq_apply_cooling(struct thermal_dev *dev,
-				int cooling_level)
-{
-	if (cooling_level < current_cooling_level) {
-		pr_err("%s: Unthrottle cool level %i curr cool %i\n",
-			__func__, cooling_level, current_cooling_level);
-		omap_thermal_step_freq_up();
-	} else if (cooling_level > current_cooling_level) {
-		pr_err("%s: Throttle cool level %i curr cool %i\n",
-			__func__, cooling_level, current_cooling_level);
-		omap_thermal_step_freq_down();
-	}
-
-	current_cooling_level = cooling_level;
-
-	return 0;
+	mutex_unlock(&omap_cpufreq_lock);
 }
-#endif
-
-#ifdef CONFIG_OMAP4_DUTY_CYCLE
 
-static struct duty_cycle_dev duty_dev = {
-	.cool_device = cpufreq_apply_cooling,
+static struct early_suspend omap_cpu_early_suspend_handler = {
+	.level = EARLY_SUSPEND_LEVEL_BLANK_SCREEN,
+	.suspend = omap_cpu_early_suspend,
+	.resume = omap_cpu_late_resume,
 };
 
-static int __init omap_duty_cooling_init(void)
-{
-	return duty_cooling_dev_register(&duty_dev);
-}
-
-static void __exit omap_duty_cooling_exit(void)
-{
-	duty_cooling_dev_unregister();
-}
-
-
-#else
-
-static int __init omap_duty_cooling_init(void) { return 0; }
-static void __exit omap_duty_cooling_exit(void) { }
-
-#endif
-
-#ifdef CONFIG_THERMAL_FRAMEWORK
-
-static struct thermal_dev_ops cpufreq_cooling_ops = {
-	.cool_device = cpufreq_apply_cooling,
-};
-
-static struct thermal_dev thermal_dev = {
-	.name		= "cpufreq_cooling",
-	.domain_name	= "cpu",
-	.dev_ops	= &cpufreq_cooling_ops,
-};
-
-static int __init omap_cpufreq_cooling_init(void)
-{
-	return thermal_cooling_dev_register(&thermal_dev);
-}
-
-static void __exit omap_cpufreq_cooling_exit(void)
+static inline void freq_table_free(void)
 {
-	thermal_governor_dev_unregister(&thermal_dev);
+	if (atomic_dec_and_test(&freq_table_users))
+		opp_free_cpufreq_table(mpu_dev, &freq_table);
 }
-#else
-static int __init omap_cpufreq_cooling_init(void) { return 0; }
-static void __exit omap_cpufreq_cooling_exit(void) { }
-#endif
 
 static int __cpuinit omap_cpu_init(struct cpufreq_policy *policy)
 {
@@ -433,7 +359,6 @@ static int __cpuinit omap_cpu_init(struct cpufreq_policy *policy)
 	for (i = 0; freq_table[i].frequency != CPUFREQ_TABLE_END; i++)
 		max_freq = max(freq_table[i].frequency, max_freq);
 	max_thermal = max_freq;
-	current_cooling_level = 0;
 
 	/*
 	 * On OMAP SMP configuartion, both processors share the voltage
